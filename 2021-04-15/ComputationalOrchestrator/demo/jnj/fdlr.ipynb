{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "durable-satellite",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sail.data import DataFrameGroup\n",
    "from sail.algo import Fdlr\n",
    "from sail.core import spawnvms, connect\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "seasonal-spouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show two data servers (vms) and an aggregation server (vmagg)\n",
    "#vms = spawnvms(3)\n",
    "#vmagg = vms[-1]\n",
    "#vms = vms[:-1]\n",
    "vm1 = connect(\"40.75.70.65\", 7000, \"lbart@igr.com\", \"sailpassword\")\n",
    "vm2 = connect(\"40.75.70.5\", 7000, \"lbart@igr.com\", \"sailpassword\")\n",
    "vmagg = connect(\"20.96.116.91\", 7000, \"lbart@igr.com\", \"sailpassword\")\n",
    "vms = [vm1, vm2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "russian-logan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4FDCC3A7718F45B781C256CB69CF3005', '8BF526F0BFE54EE09F7AC32074B3BEB2']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vm will be represented by a VM identifier, which will be used for future computations\n",
    "vms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "racial-transsexual",
   "metadata": {},
   "outputs": [],
   "source": [
    "# workplace is a local place in the file system to store temporary files, \n",
    "# which includes some parameters users input for model training\n",
    "workplace = \"/home/jjj/playground/tmp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "welsh-interpretation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataFrameGroup is the collection of all dataset distributed among the VMs.\n",
    "dfg = DataFrameGroup(vms, workplace)\n",
    "#The import_data function takes in the data IDs and import the data from the data connector\n",
    "dfg.import_data([0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "guided-approval",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 6), (5, 6)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dfg has a public data field shape, which depicts the shape of the datasets in rows and cols\n",
    "dfg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "becoming-packaging",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Index(['Region', 'Temp(F)', 'Rainfall(mm)', 'Humidity(%)', 'Apples(ton)',\n",
       "        'Oranges(ton)'],\n",
       "       dtype='object'),\n",
       " Index(['Region', 'Temp(F)', 'Rainfall(mm)', 'Humidity(%)', 'Apples(ton)',\n",
       "        'Oranges(ton)'],\n",
       "       dtype='object')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the col_label field has the fetures names of each col.\n",
    "dfg.col_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "thermal-pocket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Region          object\n",
       " Temp(F)          int64\n",
       " Rainfall(mm)     int64\n",
       " Humidity(%)      int64\n",
       " Apples(ton)      int64\n",
       " Oranges(ton)     int64\n",
       " dtype: object,\n",
       " Region          object\n",
       " Temp(F)          int64\n",
       " Rainfall(mm)     int64\n",
       " Humidity(%)      int64\n",
       " Apples(ton)      int64\n",
       " Oranges(ton)     int64\n",
       " dtype: object]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the dtypes function gives the data types of each column\n",
    "dfg.dtypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "computational-alfred",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region</th>\n",
       "      <th>Temp(F)</th>\n",
       "      <th>Rainfall(mm)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>Apples(ton)</th>\n",
       "      <th>Oranges(ton)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kanto</td>\n",
       "      <td>73</td>\n",
       "      <td>67</td>\n",
       "      <td>43</td>\n",
       "      <td>56</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Johto</td>\n",
       "      <td>91</td>\n",
       "      <td>88</td>\n",
       "      <td>64</td>\n",
       "      <td>81</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoenn</td>\n",
       "      <td>87</td>\n",
       "      <td>124</td>\n",
       "      <td>58</td>\n",
       "      <td>119</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Region  Temp(F)  Rainfall(mm)  Humidity(%)  Apples(ton)  Oranges(ton)\n",
       "0  Kanto       73            67           43           56            70\n",
       "1  Johto       91            88           64           81           101\n",
       "2  Hoenn       87           124           58          119           133"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make this part actual synthetic data\n",
    "dfg.sample(vms[0], dfg.df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "controlled-camcorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The private_intersect compute the duplicate items between two data sets, \n",
    "#the droprow function drops the duplicated terms\n",
    "duplicate = dfg.private_intersect(vms[0], vms[1], dfg.df[0], dfg.df[1], 'Region')\n",
    "dfg.df[1] = dfg.droprow(vms[1], duplicate[1], dfg.df[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "forward-punch",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We add a new feature 'Temp(C)' temperature in celsius by doing transformation from the 'Temp(F)'\n",
    "newdf = dfg.apply_and_append(['Temp(F)']*len(vms), ['Temp(C)']*len(vms), dfg.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "consecutive-marshall",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.47835011346874645"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can calculate the pearson correlation between the new feature and the target \n",
    "#to evaluate its usefulness\n",
    "dfg.pearson_corr('Temp(C)', 'Apples(ton)', newdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "reported-dominican",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can do a normal transformation on the new feature we generated\n",
    "dfg.norm_transform('Temp(C)', newdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "governing-celtic",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the features and targets cols\n",
    "#The get_col/to_numpy are done remotely\n",
    "data = {}\n",
    "X = dfg.get_col([['Temp(F)', 'Rainfall(mm)', 'Humidity(%)']]*len(vms), dfg.df)\n",
    "y = dfg.get_col([['Apples(ton)', 'Oranges(ton)']]*len(vms), dfg.df)\n",
    "data['X_train'] = dfg.to_numpy(X)\n",
    "data['y_train'] = dfg.to_numpy(y)\n",
    "#data['X_train'], data['X_test'], data['y_train'], data['y_test'] = dfg.train_test_split(X, y, 0.2, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "animated-audit",
   "metadata": {},
   "outputs": [],
   "source": [
    "#construct the model\n",
    "model_one = Fdlr(vms, vmagg, data, workplace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "furnished-defendant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing round: 1\n",
      "processing round: 10\n",
      "processing round: 19\n",
      "processing round: 28\n",
      "processing round: 37\n",
      "processing round: 46\n",
      "processing round: 55\n",
      "processing round: 64\n"
     ]
    }
   ],
   "source": [
    "#sigle round training\n",
    "model_one.initmodel(3,2,5e-5)\n",
    "#explain what fit is doing\n",
    "model_one.fit(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "suburban-athletics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.2953567504882812, 0.7586970329284668]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compute the mean absolute error\n",
    "model_one.mae(data['X_train'], data['y_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fossil-butler",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The block below does hyperparameter optimization by using Optuna package\n",
    "model_op = Fdlr(vms, vmagg, data, workplace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "strategic-drink",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trail, model):\n",
    "    n_lr = trail.suggest_float('n_lr', 1e-5, 1e-4)\n",
    "    model.initmodel(3,2,n_lr)\n",
    "    model.fit(100)\n",
    "    return model.score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "modular-fitting",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-04-15 18:49:56,980]\u001b[0m A new study created in memory with name: no-name-db7f2f1c-6202-4411-85ba-21502e55fd3f\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing round: 1\n",
      "processing round: 10\n",
      "processing round: 19\n",
      "processing round: 28\n",
      "processing round: 37\n",
      "processing round: 46\n",
      "processing round: 55\n",
      "processing round: 64\n",
      "processing round: 73\n",
      "processing round: 82\n",
      "processing round: 91\n",
      "processing round: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-04-15 18:54:12,676]\u001b[0m Trial 0 finished with value: 4.267003456751506 and parameters: {'n_lr': 2.6397712625955436e-05}. Best is trial 0 with value: 4.267003456751506.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing round: 1\n",
      "processing round: 10\n",
      "processing round: 19\n",
      "processing round: 28\n",
      "processing round: 37\n",
      "processing round: 46\n",
      "processing round: 55\n",
      "processing round: 64\n",
      "processing round: 73\n",
      "processing round: 82\n",
      "processing round: 91\n",
      "processing round: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-04-15 18:58:28,845]\u001b[0m Trial 1 finished with value: 5.76754872004191 and parameters: {'n_lr': 2.4960121595429822e-05}. Best is trial 0 with value: 4.267003456751506.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing round: 1\n",
      "processing round: 10\n",
      "processing round: 19\n",
      "processing round: 28\n",
      "processing round: 37\n",
      "processing round: 46\n",
      "processing round: 55\n",
      "processing round: 64\n",
      "processing round: 73\n",
      "processing round: 82\n",
      "processing round: 91\n",
      "processing round: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-04-15 19:02:47,076]\u001b[0m Trial 2 finished with value: 1.6436131000518799 and parameters: {'n_lr': 7.985380168418907e-05}. Best is trial 2 with value: 1.6436131000518799.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(lambda trial: objective(trial, model_op), n_trials=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continental-continuity",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show prediction?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
