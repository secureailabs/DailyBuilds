{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "turkish-humidity",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sail.data import DataFrameGroup\n",
    "from sail.algo import Fdlr\n",
    "from sail.core import spawnvms, connect\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "favorite-wright",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show two data servers (vms) and an aggregation server (vmagg)\n",
    "vm1 = connect(\"20.44.107.205\", 7000, \"lbart@igr.com\", \"sailpassword\")\n",
    "vm2 = connect(\"20.44.107.254\", 7000, \"lbart@igr.com\", \"sailpassword\")\n",
    "vmagg = connect(\"20.44.107.111\", 7000, \"lbart@igr.com\", \"sailpassword\")\n",
    "vms = [vm1, vm2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "painful-isolation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6816123528CD41A5A6675236637F72C2', '66F116B630914FB59832CE9884D00A34']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vm will be represented by a VM identifier, which will be used for future computations\n",
    "vms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "thousand-cookie",
   "metadata": {},
   "outputs": [],
   "source": [
    "# workplace is a local place in the file system to store temporary files, \n",
    "# which includes some parameters users input for model training\n",
    "workplace = \"/home/jjj/playground/tmp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cutting-adaptation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataFrameGroup is the collection of all dataset distributed among the VMs.\n",
    "dfg = DataFrameGroup(vms, workplace)\n",
    "#The import_data function takes in the data IDs and import the data from the data connector\n",
    "dfg.import_data([0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "becoming-translator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 6), (5, 6)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dfg has a public data field shape, which depicts the shape of the datasets in rows and cols\n",
    "dfg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "spare-ecuador",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Index(['Region', 'Temp(F)', 'Rainfall(mm)', 'Humidity(%)', 'Apples(ton)',\n",
       "        'Oranges(ton)'],\n",
       "       dtype='object'),\n",
       " Index(['Region', 'Temp(F)', 'Rainfall(mm)', 'Humidity(%)', 'Apples(ton)',\n",
       "        'Oranges(ton)'],\n",
       "       dtype='object')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the col_label field has the fetures names of each col.\n",
    "dfg.col_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adaptive-armenia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['32CC56FB661546ED99F429130490E9B2D8732F22BD0941F386DF3AEE048F3736',\n",
       " '161CA6F34EE049A39D0B2165598D74A0D8732F22BD0941F386DF3AEE048F3736']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfg.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "uniform-israeli",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Region          object\n",
       " Temp(F)          int64\n",
       " Rainfall(mm)     int64\n",
       " Humidity(%)      int64\n",
       " Apples(ton)      int64\n",
       " Oranges(ton)     int64\n",
       " dtype: object,\n",
       " Region          object\n",
       " Temp(F)          int64\n",
       " Rainfall(mm)     int64\n",
       " Humidity(%)      int64\n",
       " Apples(ton)      int64\n",
       " Oranges(ton)     int64\n",
       " dtype: object]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the dtypes function gives the data types of each column\n",
    "dfg.dtypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "developing-treasury",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The private_intersect compute the duplicate items between two data sets, \n",
    "#the droprow function drops the duplicated terms\n",
    "duplicate = dfg.private_intersect(vms[0], vms[1], dfg.df[0], dfg.df[1], 'Region')\n",
    "dfg.df[1] = dfg.droprow(vms[1], duplicate[1], dfg.df[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "threaded-apache",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We add a new feature 'Temp(C)' temperature in celsius by doing transformation from the 'Temp(F)'\n",
    "newdf = dfg.apply_and_append(['Temp(F)']*len(vms), ['Temp(C)']*len(vms), dfg.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "matched-geneva",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.47835011346874645"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can calculate the pearson correlation between the new feature and the target \n",
    "#to evaluate its usefulness\n",
    "dfg.pearson_corr('Temp(C)', 'Apples(ton)', newdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "revolutionary-nation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can do a normal transformation on the new feature we generated\n",
    "dfg.norm_transform('Temp(C)', newdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "short-assessment",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the features and targets cols\n",
    "#The get_col/to_numpy are done remotely\n",
    "data = {}\n",
    "X = dfg.get_col([['Temp(F)', 'Rainfall(mm)', 'Humidity(%)']]*len(vms), dfg.df)\n",
    "y = dfg.get_col([['Apples(ton)', 'Oranges(ton)']]*len(vms), dfg.df)\n",
    "data['X_train'] = dfg.to_numpy(X)\n",
    "data['y_train'] = dfg.to_numpy(y)\n",
    "#data['X_train'], data['X_test'], data['y_train'], data['y_test'] = dfg.train_test_split(X, y, 0.2, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "engaging-prototype",
   "metadata": {},
   "outputs": [],
   "source": [
    "#construct the model\n",
    "model_one = Fdlr(vms, vmagg, data, workplace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "wired-startup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing round: 1\n",
      "processing round: 10\n",
      "processing round: 19\n",
      "processing round: 28\n",
      "processing round: 37\n",
      "processing round: 46\n",
      "processing round: 55\n",
      "processing round: 64\n",
      "processing round: 73\n",
      "processing round: 82\n",
      "processing round: 91\n",
      "processing round: 100\n"
     ]
    }
   ],
   "source": [
    "#sigle round training\n",
    "model_one.initmodel(3,2,5e-5)\n",
    "#explain what fit is doing\n",
    "model_one.fit(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "exterior-winning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4131690979003906"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compute the mean absolute error\n",
    "model_one.mae(data['X_train'], data['y_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "early-journalist",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The block below does hyperparameter optimization by using Optuna package\n",
    "model_op = Fdlr(vms, vmagg, data, workplace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "broad-arcade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trail, model):\n",
    "    n_lr = trail.suggest_float('n_lr', 1e-5, 1e-4)\n",
    "    model.initmodel(3,2,n_lr)\n",
    "    model.fit(100)\n",
    "    return model.score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "useful-database",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-04-16 12:34:34,860]\u001b[0m A new study created in memory with name: no-name-36983a54-92da-4a90-b8ea-ea70d6838532\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing round: 1\n",
      "processing round: 10\n",
      "processing round: 19\n",
      "processing round: 28\n",
      "processing round: 37\n",
      "processing round: 46\n",
      "processing round: 55\n",
      "processing round: 64\n",
      "processing round: 73\n",
      "processing round: 82\n",
      "processing round: 91\n",
      "processing round: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-04-16 12:40:44,032]\u001b[0m Trial 0 finished with value: 2.5347335815429686 and parameters: {'n_lr': 7.77735837165351e-05}. Best is trial 0 with value: 2.5347335815429686.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing round: 1\n",
      "processing round: 10\n",
      "processing round: 19\n",
      "processing round: 28\n",
      "processing round: 37\n",
      "processing round: 46\n",
      "processing round: 55\n",
      "processing round: 64\n",
      "processing round: 73\n",
      "processing round: 82\n",
      "processing round: 91\n",
      "processing round: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-04-16 12:46:22,573]\u001b[0m Trial 1 finished with value: 2.8942440032958983 and parameters: {'n_lr': 6.03870188968855e-05}. Best is trial 0 with value: 2.5347335815429686.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing round: 1\n",
      "processing round: 10\n",
      "processing round: 19\n",
      "processing round: 28\n",
      "processing round: 37\n",
      "processing round: 46\n",
      "processing round: 55\n",
      "processing round: 64\n",
      "processing round: 73\n",
      "processing round: 82\n",
      "processing round: 91\n",
      "processing round: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-04-16 12:52:05,408]\u001b[0m Trial 2 finished with value: 4.319192504882812 and parameters: {'n_lr': 3.09930875201408e-05}. Best is trial 0 with value: 2.5347335815429686.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(lambda trial: objective(trial, model_op), n_trials=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flexible-apollo",
   "metadata": {},
   "outputs": [],
   "source": [
    "Thanks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
